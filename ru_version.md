# Data Science.  Взгляд на начинающих аналитиков/DSов с точки зрения компании.

### [2021] Аудитория – студенты. Опыт – 2-4 курс IT факультета.
---
[Знакомство. Ответы на заранее подготовленные вопросы студентов]

---


## - С чего начать свой путь в DS? Чему приходится доучивать начинающих аналитиков?


Начать стоит с изучения утилит и сервисов, используемых в продуктовой разработке! Вам должны быть как минимум знакомы такие слова как git, Jira, docker, AWS. Необходимо хорошо знать язык программирования, который вы будете использовать – в основном это Python, R, или Scala, а так же SQL. Библиотеки numpy, scipy, pandas в случае Python. Основы статистики и линаглебры.

Я не стал бы сильно заострять внимание на математической части и даже не библиотеках. Скажем честно – для многих присутствующих, весь текущий опыт в DS – это просмотр нескольких курсов по теории, с последующим запуском одиночного Python скрипта на [Kaggle](https://www.kaggle.com/), где на вход принимается относительно чистый CSV файл, и результат – это ещё один CSV файл.

Проблема в том, что эта среда слишком стерильна. В реальности больше половины времени уходит на очистку входных данных, и я говорю не про анализ фич, а в принципе их создание из абстрактного массива разнородных данных. Иногда их необходимо предварительно спарсить, и для этого надо знать Scrapy и lxml. К ним подтягивается условная БД для хранения данных и `docker-compose` для объединения всех частей парсера и его запуска. 

Очень сложно представить на крупном проекте изолированного DS человека, который выпрашивает готовые объединённые таблицы из продуктовой базы данных у девопса или ещё кого, потом пишет одиночный .py скрипт со строками:

```python
data = pd.read_csv(“data.csv”)
…
model = Classifier()
model.fit(X, y)
predictions = model.predict(X_test)
```

и кидает его в канал бэкенда в слаке со словами “моя работа закончена, дальше сами интегрируйте”.

Подобная изоляция возможно только если этот аналитик является квантом с PhD в финтехе, к которому приставлена команда, которая переводит его черновики с R или TeX варианта на язык используемые в проете, эта же команда адаптирует наброски под подходящие фреймворки, занимается тестированием...

Подводя итог – в целом доучивать приходится всему, что происходит на бэкенде, пусть и в более упрощённой форме – умение заворачивать скрипты в микросервисы, принципы REST, стандарты оформления кода, процесс MR, тестирование, развёртывание проекта, самостоятельное получение необходимых данных… Что касается части ML, то здесь, как правило, особых знаний и не требуется и достаточно базового понимания того, что используешь. Опять же, если это не финтех.

---

## - Чем отличается DS подход в финтехе?

Основное отличие в формате данных и в целях обучения модели. В финтехе как правило все данные уже структурированы и аналитик получает на входе то, что вы могли видеть на Kaggle. Просто потому что достаточно глупо тратить время человека с $200k+ контрактом на очистку и сбор данных. Здесь же начинается и "Kaggle подход" улучшения  – поиск лучших весов полным перебором, выбор моделей, анализ распределений, отбор признаков, регуляризация, ансамбли моделей итд. Потому что цель – это улучшить показатель какого-нибудь коэффициента Шарпа с условных 0.21533 до 0.21600. Основная логика получения данных и даже создания признаков скрыта из соображений безопасности и, конкретно в этом случае, изолированная среда кванта полностью оправдана.

---

## - Если не брать в расчёт финтех, то как улучшать модель? Есть примеры ML стека в проде?

На самом деле всё абсолютно так же - препроцессинг, учёт выбросов, распределений, алгоритмов, фич, построение PoC модели... в принципе, никто вам не запрещает после запуска PoC из 20 строк начать пару спринтов крутить веса, опции, и строить ансамбли, что можеть дать прирост в какую-то долю процента метрики. Вопрос лишь в выхлопе от этих манипуляций. Предположим, что у вас есть интернет-магазин, к которому необходимо прикрутить рекомендацию. Если следовать методичкам, то в базовом варианте – это получение из бд или через API данных, достаточных для создания матрицы “покупатель <> товар + оценка товара на пересечении”. После чего часто начинается цикл из перебора метрик расстояния, будь то косинусовая, евклидова или пирсона мера, снижение размерности (когда внезапно становится ясно, что такая матрица не влезет во всю оперативную память мира при релизе на полном наборе данных). Далее идёт перебор алгоритмов снижения размерности, полный перебора всевозможных опций этих алгоритмов, так называемая гипероптимизация, и всё в этом духе. Вся эта радость тестируется в рамках своего микросервиса на исторических данных и презентуется на каждом спринте в виде “обновлены веса модели, метрика Something@k +0.016% от прошлого результата”.

Единственная проблема только в том, что потрачен уже н-ный месяц разработки, а глобального ничего не улучшается – продажи падают, пользователи рекомендованные товары не выбирают, и вообще зрительно они выглядят нерелевантными. Осознание этого факта обычно знаменует выход дата саентиста за пределы улучшения модели. Начинается проверка по чек-листу:

*	Проверка того, что модель действительно пошла в прод в том виде, в котором её задумал DS (Требуется знание ЯП проекта, умение ковырять API прода через `Postman`, а так же умение взаимодействовать с лидом бэкенда и девопсом). Как можно избежать этого?  - DS сидит на мерж реквесте интеграции своего сервиса в проект и активно участвует в нём на месте проверяющего, либо сам создаёт MR.

* 	Тестирование на исторических данных некорректно в силу того, что в давние времена покупателям с бэка приходило 10 товаров во старой системе рекомендации, но фронт взял на себя ответственность не показывать последние 5, так как вёрстку ломало, ну и нерелевантные же зрительно. (Требуется знание истории проекта и взаимодействие DS со всеми отделами) В целом подобное решается ведением снапшотов проекта, что требует участие всех отделов.

*	Некорректна метрика / для создание метрики не хватает данных. (Опять же требуется понимание проекта целиком, а так же знание пути, который проходит покупатель) К примеру, можно создать тикет с реквестом на создание кнопки “нерелевантно” рядом с товаром или добавить аналитику кликов, что даст дополнительные позитивные и негативные сигналы для модели. Так же имеет смысл спросить у отдела продаж или менеджеров, что с их точки зрения является метрикой олицетворяющей “успех” - это может быть скорость роста продаж, количество новыех клиентов, или какие-то вообще неожиданные соотношения чего-либо к чему-то. Не факт, что эту метрику надо будет использовать для оптимизации параметров, но весьма полезно смотреть на корреляцию метрики “успеха” с метрикой обучения.

*	 Необходимы дополнительные микросервисы – к примеру, можно вспомогательно смотреть на кластеры товаров, для чего может потребоваться NLP и советовать товары из одного кластера. Или ещё лучше взять готовую универсальную классификацию наподобие UNSPSC и выбрав любой классификатор (уже не повторяя подход с бесконечной гипероптимизацией) создать дополнительные датасеты. Аугментация данных – продукт может рекомендоваться из схемы “Покупатель часто покупал продукты производителя Х → рекомендуем другие продукты с высокими оценками производителя Х из категории Y в которой покупатель был активен” Дополнительные данные делим в пропорции 70% - семантически схожи с продуктами, которые были куплены или которые были кликнуты мышью или как-то иначе позитивно отмечены на UI покупателем, 30% случайные популярные на данный момент товары из категории Y. Добавляем учёт цен, скидок, сезонности, прочих групп, будь то совпадение страны производителя и покупателя, наличие доставки, время дня, наличие или отсутствие отзывов, и так далее, и так далее. (И вот для этого требуется знание сферы, в которой работает DS).

Касательно вопроса о стеке – всё ранее сказанное, опуская библиотеки, может быть представлено в виде
    
`DataLake` → `MLFlow`/`AWS_Sagemaker`(`docker_image`(`fastAPI`(`model`)→`REST`)) <-> core app. + `Elasticsearch` + BI tool (`looker`/`tableau`) + `Datadog` + `Grafana`

\+ подключение `Apache software` в случае высокой нагрузки, но я не видел случаев, где условные `spark` или `hadoop` были бы реально нужны, очень часто мощность потока данных переоценивается при выборе инструментария обработки. CI/CD, версионирование и релиз моделей в целом, на человеке, которого мы будем звать MLOps, роуты A/B тестирования и снапшоты скорее на DevOps и бэкенд-команде. По итогу всё это позволяет выстроить 3 уровня аналитики – уровень платформы, уровень команды разработки и продаж, и уровень наблюдения за компанией (информаци для топ менеджеров и инвесторов).

Выполнение любого пункта из этого чек-листа зачастую даёт гораздо больше пользы, чем улучшение отдельно взятой модели на 0.000х% accuracy. Поэтому при наборе в DS меня обычно больше интересовал ход мысли кандидата и умения, которые казалось бы не относятся к DS сфере, но по факту относятся. В каком-то роде проще научить бэкендера мудростям аналитики, чем наоборот.

Не могу сказать, что полностью игнорирую математические скилы, например считаю очень полезным понимание распределений, выбросов, геометрической интерпретации классификации и регрессии, а так же умение выбора подходящих метрик и алгоритмов. Но в вопроса рода “Как строятся деревья в градиентном бустинге?” большого смысла не вижу.

---

## - Что добавляли в тестовое задание?

Что-то практическое, к примеру очистка данных и их стандартизация. Многое можно сказать о ходе мыслей кандидата, смотря на методы очистки – можно их использовать повторно или нет, например. Были случаи, когда логика приведения данных в порядок выглядела как: “на седьмой строке удалить символы с 10 по 15”,  но были и универсальные функции с regexами, которые можно было хоть сейчас добавлять на рабочий проект. То есть в целом, это были довольно абстрактные задачи с полной свободой в их решении, где в максимальном варианте я бы хотел видеть докеризированое приложение, включающее в себя простенький парсер, модуль очистки и классификатор. Абсолютно всё могло быть скопировано с первой взятой ссылки с гугла по запросу "classificator + sklearn" и сделано менее чем за час.

Большое значение имеет качество кода и понимание поставленной цели. Бонусы за креативность, вроде аугментирования данных или подключение фреймворков, которые решают задачу в три строки. Разница лабораторных и реальных задач в том, что в первом случае вам нужно самостоятельно с нуля разработать всё, что бы понять логику на самом низком уровне. Во втором случае от вас требуется решение поставленной бизнесом задачи, если она решается импортом известной библиотеки с добавлением пары строк кода – это только плюс. Больше времени на тестирование и интеграцию.
